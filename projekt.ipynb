{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Podstawy Sztucznej Inteligencji - Projekt Kacper Marzol"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Celem tego projektu jest klasyfikacja piosenek na podstawie ich kilku cech. Zbiór danych składa się z 278 tysięcy piosenek z serwisu Spotify."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(277938, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Unnamed: 0.1  Unnamed: 0  duration (ms)  danceability  energy  loudness  \\\n0             0           0       195000.0         0.611   0.614    -8.815   \n1             1           1       194641.0         0.638   0.781    -6.848   \n2             2           2       217573.0         0.560   0.810    -8.029   \n3             3           3       443478.0         0.525   0.699    -4.571   \n4             4           4       225862.0         0.367   0.771    -5.863   \n\n   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n0       0.0672        0.0169          0.000794    0.7530    0.520  128.050   \n1       0.0285        0.0118          0.009530    0.3490    0.250  122.985   \n2       0.0872        0.0071          0.000008    0.2410    0.247  170.044   \n3       0.0353        0.0178          0.000088    0.0888    0.199   92.011   \n4       0.1060        0.3650          0.000001    0.0965    0.163  115.917   \n\n      spec_rate  labels                                   uri  \n0  3.446154e-07       2  spotify:track:3v6sBj3swihU8pXQQHhDZo  \n1  1.464234e-07       1  spotify:track:7KCWmFdw0TzoJbKtqRRzJO  \n2  4.007850e-07       1  spotify:track:2CY92qejUrhyPUASawNVRr  \n3  7.959809e-08       0  spotify:track:11BPfwVbB7vok7KfjBeW4k  \n4  4.693131e-07       1  spotify:track:3yUJKPsjvThlcQWTS9ttYx  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>duration (ms)</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>spec_rate</th>\n      <th>labels</th>\n      <th>uri</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>195000.0</td>\n      <td>0.611</td>\n      <td>0.614</td>\n      <td>-8.815</td>\n      <td>0.0672</td>\n      <td>0.0169</td>\n      <td>0.000794</td>\n      <td>0.7530</td>\n      <td>0.520</td>\n      <td>128.050</td>\n      <td>3.446154e-07</td>\n      <td>2</td>\n      <td>spotify:track:3v6sBj3swihU8pXQQHhDZo</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>194641.0</td>\n      <td>0.638</td>\n      <td>0.781</td>\n      <td>-6.848</td>\n      <td>0.0285</td>\n      <td>0.0118</td>\n      <td>0.009530</td>\n      <td>0.3490</td>\n      <td>0.250</td>\n      <td>122.985</td>\n      <td>1.464234e-07</td>\n      <td>1</td>\n      <td>spotify:track:7KCWmFdw0TzoJbKtqRRzJO</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>217573.0</td>\n      <td>0.560</td>\n      <td>0.810</td>\n      <td>-8.029</td>\n      <td>0.0872</td>\n      <td>0.0071</td>\n      <td>0.000008</td>\n      <td>0.2410</td>\n      <td>0.247</td>\n      <td>170.044</td>\n      <td>4.007850e-07</td>\n      <td>1</td>\n      <td>spotify:track:2CY92qejUrhyPUASawNVRr</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>443478.0</td>\n      <td>0.525</td>\n      <td>0.699</td>\n      <td>-4.571</td>\n      <td>0.0353</td>\n      <td>0.0178</td>\n      <td>0.000088</td>\n      <td>0.0888</td>\n      <td>0.199</td>\n      <td>92.011</td>\n      <td>7.959809e-08</td>\n      <td>0</td>\n      <td>spotify:track:11BPfwVbB7vok7KfjBeW4k</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>225862.0</td>\n      <td>0.367</td>\n      <td>0.771</td>\n      <td>-5.863</td>\n      <td>0.1060</td>\n      <td>0.3650</td>\n      <td>0.000001</td>\n      <td>0.0965</td>\n      <td>0.163</td>\n      <td>115.917</td>\n      <td>4.693131e-07</td>\n      <td>1</td>\n      <td>spotify:track:3yUJKPsjvThlcQWTS9ttYx</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"278k_labelled_uri.csv\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Unnamed: 0.1', 'Unnamed: 0', 'duration (ms)', 'danceability', 'energy',\n       'loudness', 'speechiness', 'acousticness', 'instrumentalness',\n       'liveness', 'valence', 'tempo', 'spec_rate', 'labels', 'uri'],\n      dtype='object')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Acousticness: miara akustyczności od 0 do 1\n",
    "Danceability: miara taneczności od 0 do 1\n",
    "Energy: miara energiczności od 0 do 1\n",
    "Instrumentalness: miara instrumentalności od 0 do 1\n",
    "Liveness: miara obecności publiki w nagraniu od 0 do 1\n",
    "Loudness: miara głośnośći w decybelach (-60 do 0 decybeli)\n",
    "Speechiness: miara słów w piosence od 0 do 1\n",
    "Valence: miara od 0 do 1 opisująca pozytywność przekazywaną przez piosenkę\n",
    "Tempo: tempo piosenki w BMP (uderzeń na minutę)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "1    106429\n0     82058\n2     47065\n3     42386\nName: labels, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.labels.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0 - piosenka smutna\n",
    "1 - piosenka wesoła\n",
    "2 - piosenka energetyczna\n",
    "3 - piosenka spokojna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Usuniemy zbędne kolumny, \"uri\", ponieważ URL piosenki nie jest potrzebny oraz dwie pierwsze kolumny"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cols=[\"Unnamed: 0.1\", \"Unnamed: 0\",\"uri\"]\n",
    "data=data.drop(cols ,axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   duration (ms)  danceability  energy  loudness  speechiness  acousticness  \\\n0       195000.0         0.611   0.614    -8.815       0.0672        0.0169   \n1       194641.0         0.638   0.781    -6.848       0.0285        0.0118   \n2       217573.0         0.560   0.810    -8.029       0.0872        0.0071   \n3       443478.0         0.525   0.699    -4.571       0.0353        0.0178   \n4       225862.0         0.367   0.771    -5.863       0.1060        0.3650   \n\n   instrumentalness  liveness  valence    tempo     spec_rate  labels  \n0          0.000794    0.7530    0.520  128.050  3.446154e-07       2  \n1          0.009530    0.3490    0.250  122.985  1.464234e-07       1  \n2          0.000008    0.2410    0.247  170.044  4.007850e-07       1  \n3          0.000088    0.0888    0.199   92.011  7.959809e-08       0  \n4          0.000001    0.0965    0.163  115.917  4.693131e-07       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration (ms)</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>spec_rate</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>195000.0</td>\n      <td>0.611</td>\n      <td>0.614</td>\n      <td>-8.815</td>\n      <td>0.0672</td>\n      <td>0.0169</td>\n      <td>0.000794</td>\n      <td>0.7530</td>\n      <td>0.520</td>\n      <td>128.050</td>\n      <td>3.446154e-07</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>194641.0</td>\n      <td>0.638</td>\n      <td>0.781</td>\n      <td>-6.848</td>\n      <td>0.0285</td>\n      <td>0.0118</td>\n      <td>0.009530</td>\n      <td>0.3490</td>\n      <td>0.250</td>\n      <td>122.985</td>\n      <td>1.464234e-07</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>217573.0</td>\n      <td>0.560</td>\n      <td>0.810</td>\n      <td>-8.029</td>\n      <td>0.0872</td>\n      <td>0.0071</td>\n      <td>0.000008</td>\n      <td>0.2410</td>\n      <td>0.247</td>\n      <td>170.044</td>\n      <td>4.007850e-07</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>443478.0</td>\n      <td>0.525</td>\n      <td>0.699</td>\n      <td>-4.571</td>\n      <td>0.0353</td>\n      <td>0.0178</td>\n      <td>0.000088</td>\n      <td>0.0888</td>\n      <td>0.199</td>\n      <td>92.011</td>\n      <td>7.959809e-08</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>225862.0</td>\n      <td>0.367</td>\n      <td>0.771</td>\n      <td>-5.863</td>\n      <td>0.1060</td>\n      <td>0.3650</td>\n      <td>0.000001</td>\n      <td>0.0965</td>\n      <td>0.163</td>\n      <td>115.917</td>\n      <td>4.693131e-07</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dodamy trochę nanów do zbioru"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "duration (ms)       27555\ndanceability        28093\nenergy              27824\nloudness            27713\nspeechiness         27787\nacousticness        27793\ninstrumentalness    27861\nliveness            27950\nvalence             27607\ntempo               27731\nspec_rate           27818\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "X = data.drop('labels', axis=1)\n",
    "y = data.labels\n",
    "\n",
    "ix = [(row, col) for row in range(X.shape[0]) for col in range(X.shape[1])]\n",
    "for row, col in random.sample(ix, int(round(.1*len(ix)))):\n",
    "    X.iat[row, col] = np.nan\n",
    "\n",
    "X.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podzielimy zbiór na część treningową, walidacyjną i testową:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(222350, 11)\n",
      "(222350,)\n",
      "(27794, 11)\n",
      "(27794, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xplot=X_train.iloc[:50, :]\n",
    "sns.pairplot(xplot)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nauczymy kilka modeli"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pipeline = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "models=[]\n",
    "scores=[]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def pipeline_maker(model):\n",
    "    return make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(),model)\n",
    "\n",
    "def test (model, param_grid_):\n",
    "    pipe=pipeline_maker(model)\n",
    "    search=GridSearchCV(pipe, param_grid=param_grid_,scoring='accuracy')\n",
    "    search.fit(X_train, y_train)\n",
    "    return search.best_params_\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[100], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(params)\n\u001B[1;32m     12\u001B[0m logistic\u001B[38;5;241m=\u001B[39mLogisticRegression(C\u001B[38;5;241m=\u001B[39mparams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogisticregression__C\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 13\u001B[0m \u001B[43mlogistic\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m models\u001B[38;5;241m.\u001B[39mappend(logistic)\n\u001B[1;32m     16\u001B[0m scores\u001B[38;5;241m.\u001B[39mappend(accuracy_score(y_val,logistic\u001B[38;5;241m.\u001B[39mpredict(X_val)))\n",
      "File \u001B[0;32m~/miniconda3/envs/AILAB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1138\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1135\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1136\u001B[0m     _dtype \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39mfloat64, np\u001B[38;5;241m.\u001B[39mfloat32]\n\u001B[0;32m-> 1138\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1139\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1140\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1141\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1142\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1143\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1144\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mliblinear\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msag\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msaga\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1145\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1146\u001B[0m check_classification_targets(y)\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y)\n",
      "File \u001B[0;32m~/miniconda3/envs/AILAB/lib/python3.10/site-packages/sklearn/base.py:596\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    594\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 596\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    597\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[0;32m~/miniconda3/envs/AILAB/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1069\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[1;32m   1070\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1071\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1072\u001B[0m     )\n\u001B[0;32m-> 1074\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1088\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1090\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m   1092\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[0;32m~/miniconda3/envs/AILAB/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    893\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    894\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    895\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    896\u001B[0m         )\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 899\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    901\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    902\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    903\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    904\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    907\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[0;32m~/miniconda3/envs/AILAB/lib/python3.10/site-packages/sklearn/utils/validation.py:146\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    125\u001B[0m             \u001B[38;5;129;01mnot\u001B[39;00m allow_nan\n\u001B[1;32m    126\u001B[0m             \u001B[38;5;129;01mand\u001B[39;00m estimator_name\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    130\u001B[0m             \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    131\u001B[0m             \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    132\u001B[0m             msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    133\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    134\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    144\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    145\u001B[0m             )\n\u001B[0;32m--> 146\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n\u001B[1;32m    148\u001B[0m \u001B[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nan:\n",
      "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic=LogisticRegression()\n",
    "\n",
    "param_grid={\n",
    "    \"logisticregression__C\": [0.0001,0.001,0.01,0.1,1,10,100,1000]\n",
    "}\n",
    "\n",
    "params=test(logistic, param_grid)\n",
    "\n",
    "print(params)\n",
    "logistic=LogisticRegression(C=params['logisticregression__C'])\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "models.append(logistic)\n",
    "scores.append(accuracy_score(y_val,logistic.predict(X_val)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ailab",
   "language": "python",
   "display_name": "AILAB"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
